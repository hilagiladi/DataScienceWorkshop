{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443e50c4366ee5c3",
   "metadata": {},
   "source": [
    "# Intro\n",
    "As computer science students with a deep interest in data science, we, Hila Giladi (add id) and Kfir Shuster (add id), have chosen to focus on sleep duration.\n",
    "Recognizing that quality sleep is crucial for everyone's daily functioning and overall health, we are committed to leveraging data science to help people worldwide achieve better sleep patterns and, consequently, improve their quality of life.\n",
    "\n",
    "# The problem\n",
    "In our modern world, where the boundaries between day and night blur and the demanding requirements of digital life continue to grow, we are witnessing an alarming sleep crisis that is intensifying. The data collected in our research presents a particularly troubling picture: an average of just 4.5 hours of sleep - a concerning and significant gap from the accepted medical recommendation of 7-9 hours of sleep per day. This chronic lack of sleep reflects the complex reality of contemporary society, where technology, work pressures, and the desire to accomplish everything push sleep to the bottom of our priority list. The factors contributing to this crisis are diverse and intertwined: from the blue screens illuminating our lives until late night hours, through demanding jobs requiring 24/7 availability, to the constant social pressure to stay connected and active. This phenomenon gains additional significance in the global era, where time zones blur and the expectation for immediate response has become the norm. The data at our disposal serves as a wake-up call - literally and figuratively - compelling us to confront the implications of the \"always awake\" culture we've developed, and to seek creative and sustainable solutions that will allow us to rebalance our natural sleep-wake cycle.\n",
    "\n",
    "\n",
    "# The importance of the solution\n",
    "Sleep is a fundamental aspect of human health and well-being, with particular significance for mental health.\n",
    "\n",
    "\n",
    "# How we're going to do it:\n",
    "This project aims to develop a predictive model for sleep duration using a comprehensive dataset that captures various physiological, behavioral, and environmental factors. The dataset includes continuous monitoring of multiple variables including heart rate, blood pressure, skin temperature, activity levels, and various lifestyle and mental health indicators.\n",
    "By leveraging machine learning techniques to predict sleep duration, we aim to:\n",
    "1. Identify key factors that influence sleep patterns\n",
    "2. Understand the relationship between daily activities, stress levels, and sleep duration\n",
    "3. Develop a model that can potentially help in early intervention for sleep-related issues\n",
    "The dataset's unique combination of physiological measurements (heart rate, blood pressure, skin temperature), behavioral metrics (activity levels, social interaction), and mental health indicators (stress level, mental health status, resilience factors) provides a rich foundation for exploring the complex interplay between various life factors and sleep patterns.\n",
    "Through this analysis, we hope to contribute to the broader understanding of sleep health and potentially develop tools that could help individuals and healthcare providers in monitoring and improving sleep patterns, particularly in the context of mental health management.\n",
    "\n",
    "# Data Collection and Selection Process\n",
    "Before beginning our research, we needed to find the right dataset for analyzing sleep patterns. We searched through many different datasets from health organizations and research groups, looking at how well each one could help us understand sleep patterns. Our goal was to find data that would tell us the most complete story about sleep and what affects it. After reviewing many options, we chose this dataset because it gives us an excellent mix of different types of information. It tracks physical measurements like heart rate and blood pressure, along with important details about people's daily lives - their work hours, stress levels, and how they're feeling. What made this dataset stand out was that it collects information every hour and includes both physical health measurements and mental well-being indicators. This means we can look at how sleep connects to many different parts of people's lives. With over 52,000 entries, the dataset is large enough to help us find reliable patterns and connections. We believe this rich combination of different types of information will help us better understand what affects people's sleep and how we might be able to improve it."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Analysis\n",
    "Let's transform our collected data into a structured pandas data frame to examine the information we've gathered. This will give us a clear view of our dataset's contents and help us understand what we're working with."
   ],
   "id": "5e06eb63e24818cc"
  },
  {
   "cell_type": "code",
   "id": "b74b8d003c044401",
   "metadata": {},
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c8bd697e23b8a0d",
   "metadata": {},
   "source": [
    "# read data_base\n",
    "df = pd.read_csv('mental_health_monitoring_dataset.csv')\n",
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b3679a23719f95ca",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "Let’s remove all the rows with nan values:"
   ]
  },
  {
   "cell_type": "code",
   "id": "e013c705d48793cf",
   "metadata": {},
   "source": [
    "original_len = len(df)\n",
    "df = df.dropna()\n",
    "print(f\"number of removed rows: {original_len - len(df)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bae8c1fc49145693",
   "metadata": {},
   "source": [
    "As we can see there are no rows with nan values.\n",
    "Let's check for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "id": "869d1f70ea04a9d6",
   "metadata": {},
   "source": [
    "df[df.duplicated()].shape[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4884b431024b4b07",
   "metadata": {},
   "source": [
    "As we can see there are no duplicates rows in the dataset.\n",
    "\n",
    "Let’s see how many different values there are in our prediction column, Sleep_Duration:"
   ]
  },
  {
   "cell_type": "code",
   "id": "6007985a7d7c7521",
   "metadata": {},
   "source": [
    "df['Sleep_Duration'].unique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41cf559123a4490b",
   "metadata": {},
   "source": [
    "The current output is an array with all the different values in the column Sleep_Duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe324365a98182e",
   "metadata": {},
   "source": [
    "Delete rows with outliers values in the prediction column, Sleep Duration < 1"
   ]
  },
  {
   "cell_type": "code",
   "id": "c89680b605fbea30",
   "metadata": {},
   "source": [
    "original_len = len(df)\n",
    "df = df[df['Sleep_Duration'] >= 1]\n",
    "print(f\"number of removed rows: {original_len - len(df)}\")\n",
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b10467713eef340a",
   "metadata": {},
   "source": [
    "Delete irrelevant columns:\n",
    "'Location_Longitude', 'Location_Latitude', 'Fuel_Consumption', 'Timestamp', 'Galvanic_Skin_Response'\n",
    "We decided to delete those columns because they have no effect on sleep duration."
   ]
  },
  {
   "cell_type": "code",
   "id": "8bea6667cb714459",
   "metadata": {},
   "source": [
    "df = df.drop(['Location_Longitude', 'Location_Latitude', 'Fuel_Consumption', 'Timestamp', 'Galvanic_Skin_Response'], axis=1)\n",
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "509b48290b5db6f0",
   "metadata": {},
   "source": [
    "Delete rows with outlier values, skin temperatures below 35 are unusual.\n",
    "Let's remove those rows."
   ]
  },
  {
   "cell_type": "code",
   "id": "ea56091f7d8b9262",
   "metadata": {},
   "source": [
    "original_len = len(df)\n",
    "df = df[df['Skin_Temperature'] >= 35]\n",
    "print(f\"number of removed rows: {original_len - len(df)}\")\n",
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d338187f2cd11b5",
   "metadata": {},
   "source": [
    "Remove records where the values in the columns Mood and Stress_Level are logically incompatible\n",
    "   1. Mood is 'High' and Stress_Level is either 'Anxious', 'Sad', or 'Irritable'\n",
    "   2. Mood is 'Low' and Stress_Level is 'Happy'"
   ]
  },
  {
   "cell_type": "code",
   "id": "74c40249eab8beb7",
   "metadata": {},
   "source": [
    "original_len = len(df)\n",
    "df = df[\n",
    "    ~((df['Mood'] == 'High') & df['Stress_Level'].isin(['Anxious', 'Sad', 'Irritable'])) &\n",
    "    ~((df['Mood'] == 'Low') & (df['Stress_Level'] == 'Happy'))\n",
    "]\n",
    "print(f\"number of removed rows: {original_len - len(df)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "233651f0032a2fb8",
   "metadata": {},
   "source": [
    "Change text values to numeric values in the columns Driving_Conditions, Stress_Level, Mental_Health_History, Mental_Health_Status, Mood"
   ]
  },
  {
   "cell_type": "code",
   "id": "be57689e1caeb4c2",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "columns_to_encode = ['Driving_Conditions', 'Stress_Level', 'Mental_Health_History', 'Mental_Health_Status', 'Mood']\n",
    "# for transform new data later with same encodings or reverse the numeric values back to text\n",
    "encoders = {}\n",
    "mapping_text_to_numeric = {}\n",
    "\n",
    "for col in columns_to_encode:\n",
    "    encoders[col] = LabelEncoder()\n",
    "    df[col] = encoders[col].fit_transform(df[col])\n",
    "    # mapping dictionary\n",
    "    mapping_text_to_numeric = dict(zip(encoders[col].classes_, encoders[col].transform(encoders[col].classes_)))\n",
    "\n",
    "print(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69cc6403197c322c",
   "metadata": {},
   "source": [
    "Categorize numeric values in the column Activity_Levels"
   ]
  },
  {
   "cell_type": "code",
   "id": "200850463de09da",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "df['Activity_Levels'] = np.where(df['Activity_Levels'] <= 3000, 1, np.where(df['Activity_Levels'] <= 10000, 2, 3))\n",
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6055c811c63b6a86",
   "metadata": {},
   "source": [
    "Normalize the numeric values in the columns Heart_Rate, Blood_Pressure_systolic, Blood_Pressure_diastolic"
   ]
  },
  {
   "cell_type": "code",
   "id": "77dff4120b52656a",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns_to_normalize = ['Heart_Rate', 'Blood_Pressure_Systolic', 'Blood_Pressure_Diastolic']\n",
    "scaler = MinMaxScaler()\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
